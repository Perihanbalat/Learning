{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start of this discussion of transformers consider the following toy dataset, which we will refer to as our corpus, consisting of 4 documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "          'This is the second second document.',\n",
    "          'And the third one.',\n",
    "          'Is this the first document?',\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is currently not in a state where we can use it to train a predictive model. To prepare the data for modelling we can use a transformer. An sklearn transformer is any object with both a 'fit' method, which learns the transform parameters, and a 'transform' method, which applies the transform. This is similar to the sklearn estimator object, which has both a 'fit' and a 'predict' method. In this case the fit method learns the model parameters, and the predict method predicts the target variable. Slightly confusingly, sklearn will also refer to transformers as a type of estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the procedure for using a transformer is as follows\n",
    "\n",
    "# initilise an instance of our desired transformer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# fit the transformer to learn the necessary parameters\n",
    "cv.fit(corpus)\n",
    "\n",
    "# apply the transform\n",
    "X_train_transformed = cv.transform(corpus)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data which was formerly a list of strings is now a sparse matrix. It's easier to see what has happened if we convert the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         1      0   1    0       2    1      0     1\n",
       "2    1         0      0   0    1       0    1      1     0\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = pd.DataFrame(X_train_transformed.toarray(),\n",
    "                 columns=cv.get_feature_names()\n",
    "                )\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "The data has been transformed into a 'bag of words' respresentation. Our original data only had one feature (the text contained within the document) whereas now it has 9 (each unique word present in our corpus). The entry for each sample is how many times that feature/word appears in that document. When we apply the fit method of CountVectoriser, we are learning all of the unique words in our corpus. There are numerous other examples of transformers in the sklearn library. For instance, many preprossessing, dimension reduction, and feature engineering methods are implemented as transformers.\n",
    "\n",
    "You can also make your own custom transformer classes. Below is an example that transforms a sparse matrix into a dense one. If you are not familiar with classes this article is a good intro:\n",
    "https://realpython.com/python3-object-oriented-programming/#classes-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class ToDenseTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    # define the transform operation\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # no paramter to learn this case\n",
    "    # fit just returns an unchanged object\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines are a convenient way to chain together multiple transformers sequentially. The only restriction is that the final step in the pipeline must be an estimator object with a predict method. To demonstrate how to make and use a pipeline we will use the 20 Newsgroups dataset. The modelling task is to classify a document as being about religon or athiesm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# downloading the data\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "\n",
    "training_data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "X_train = training_data.data\n",
    "Y_train = training_data.target\n",
    "\n",
    "testing_data = fetch_20newsgroups(subset='test', categories=categories)\n",
    "X_test = testing_data.data\n",
    "Y_test = testing_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# create pipeline object\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"countvectorize\", CountVectorizer()), \n",
    "        (\"logreg\", LogisticRegression(solver='liblinear'))\n",
    "    ]\n",
    ")\n",
    "# the main input argument when you initiate an instance of a pipeline class is a list of tuples\n",
    "\n",
    "# each tuple is one of the steps in the pipeline. The first element of the tuple is the desired name of the step, the second element is the transformer or estimator object.\n",
    "\n",
    "# once the pipeline has been created it behaves like an estimator\n",
    "\n",
    "# call the fit method on the whole pipeline\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# this sequentially fits the data, transforms it, and passes it to the next object in the pipeline. In the final step the predictive model is fitted. This allows you to wrap up your data processing and your estimator into one object. This means you to make predictions directly on unprocessed data.\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# when you call the predict method, the data is sequentially transformed by all of the previously fit transformers in the pipeline before it is passed to the estimator for a prediction of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also use the score method, which will access the estimator's score method within the pipeline. In this case the classification accuracy is the score metric.\n",
    "pipeline.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
